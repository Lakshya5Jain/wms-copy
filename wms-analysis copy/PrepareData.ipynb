{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOCUMENTATION - https://docs.trackstarhq.com/introduction\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "# set openai api key\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "TRACKSTAR_API_KEY = os.getenv(\"TRACKSTAR_API_KEY\")\n",
    "\n",
    "# Files will be saved in the current directory\n",
    "print(f\"CSV files will be saved in: {Path.cwd()}\")\n",
    "#Get this information from the web portal \n",
    "customer_id = \"shipcalm_lookoptic\"\n",
    "connection_id = \"ab896808e6d1495b82dbfdf9f8435572\"\n",
    "integration_name = \"Infoplus\"\n",
    "access_token = \"trackstar_eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjb25uZWN0aW9uX2lkIjoiYWI4OTY4MDhlNmQxNDk1YjgyZGJmZGY5Zjg0MzU1NzIiLCJpbnRlZ3JhdGlvbl9uYW1lIjoiaW5mb3BsdXMifQ.75BBuw4TwKaccpXN_xWrOCyO1PkkwlTGgBk1LLv7UIA\"\n",
    "#Get available actions for the integration\n",
    "url = \"https://production.trackstarhq.com/wms/integrations/\"+integration_name.lower()\n",
    "headers = {\"x-trackstar-api-key\": TRACKSTAR_API_KEY}\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "#response.json()['data'][0]['available_actions']\n",
    "def paginate_endpoint(endpoint,page_token):\n",
    "    print(page_token)\n",
    "    url = \"https://production.trackstarhq.com/wms/\"+endpoint\n",
    "    headers = {\n",
    "            \"x-trackstar-api-key\": TRACKSTAR_API_KEY,\n",
    "            \"x-trackstar-access-token\": access_token\n",
    "        }\n",
    "\n",
    "    if page_token:\n",
    "        querystring = {\"page_token\":page_token}\n",
    "        response = requests.request(\"GET\", url, headers=headers,params=querystring)\n",
    "    else:\n",
    "        response = requests.request(\"GET\", url, headers=headers)\n",
    "    \n",
    "    return response\n",
    "def get_data(endpoint):\n",
    "    output = []\n",
    "    response = paginate_endpoint(endpoint,\"\")\n",
    "    output = output + response.json()['data']\n",
    "    page_token = response.json()['next_token']\n",
    "    while page_token:\n",
    "        response = paginate_endpoint(endpoint,page_token)\n",
    "        output = output + response.json()['data']\n",
    "        page_token = response.json()['next_token']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Inventory\n",
    "############################\n",
    "output = get_data(\"inventory\")\n",
    "for row in output:\n",
    "    row[\"substitute_skus\"]           = str(row[\"substitute_skus\"])\n",
    "    row[\"inventory_by_warehouse_id\"] = str(row[\"inventory_by_warehouse_id\"])\n",
    "    row[\"lots\"]                      = str(row[\"lots\"])\n",
    "    row[\"measurements\"]              = str(row[\"measurements\"])\n",
    "    row[\"locations\"]                 = str(row[\"locations\"])\n",
    "df = pd.DataFrame.from_records(output,index=[\"id\",\"warehouse_customer_id\",\"created_date\",\"updated_date\",\"name\",\"sku\",\"active\",\"awaiting\",\"onhand\",\"committed\",\"unfulfillable\",\"fulfillable\",\"unsellable\",\"sellable\",\"substitute_skus\",\"inventory_by_warehouse_id\",\"lots\",\"measurements\",\"locations\",\"external_system_url\"]) \n",
    "df.to_csv(\"inventory.csv\")   \n",
    "###########################\n",
    "# Products\n",
    "############################\n",
    "output = get_data(\"products\")\n",
    "for row in output:\n",
    "    row[\"inventory_items\"]   = str(row[\"inventory_items\"])\n",
    "    row[\"supplier_products\"] = str(row[\"supplier_products\"])\n",
    "df = pd.DataFrame.from_records(output,index=[\"id\",\"warehouse_customer_id\",\"created_date\",\"updated_date\",\"name\",\"sku\",\"gtin\",\"inventory_items\",\"is_kit\",\"active\",\"supplier\",\"country_of_origin\",\"harmonized_code\",\"supplier_products\",\"external_system_url\"]) \n",
    "df.to_csv(\"products.csv\")\n",
    "############################\n",
    "# Shipping Methods\n",
    "############################\n",
    "output = get_data(\"shipping-methods\")\n",
    "df = pd.DataFrame.from_records(output,index=['id', 'created_date','updated_date','name','carrier']) \n",
    "df.to_csv(\"shipping_methods.csv\")\n",
    "############################\n",
    "# Shipment Suppliers\n",
    "############################\n",
    "output = get_data(\"inbound-shipments/suppliers\")\n",
    "df = pd.DataFrame.from_records(output,index=['id', 'created_date','updated_date']) \n",
    "df.to_csv(\"suppliers.csv\")\n",
    "############################\n",
    "# Inbound Shipments\n",
    "############################\n",
    "output = get_data(\"inbound-shipments\")\n",
    "for row in output:\n",
    "    row[\"line_items\"]         = str(row[\"line_items\"])\n",
    "    row[\"receipts\"]           = str(row[\"receipts\"])\n",
    "    row[\"ship_from_address\"]  = str(row[\"ship_from_address\"])\n",
    "    row[\"tracking_numbers\"]   = str(row[\"tracking_numbers\"])\n",
    "    row[\"notes\"]              = str(row[\"notes\"])\n",
    "df = pd.DataFrame.from_records(output,index=[\"id\",\"warehouse_customer_id\",\"created_date\",\"updated_date\",\"purchase_order_number\",\"status\",\"raw_status\",\"supplier\",\"expected_arrival_date\",\"warehouse_id\",\"line_items\",\"receipts\",\"ship_from_address\",\"tracking_numbers\",\"notes\",\"external_system_url\"]) \n",
    "df.to_csv(\"inbound_shipments.csv\")\n",
    "############################\n",
    "# Order Channels\n",
    "############################\n",
    "output = get_data(\"orders/channels\")\n",
    "#for row in output:\n",
    "#    row[\"line_items\"]         = str(row[\"line_items\"])\n",
    "#    row[\"receipts\"]           = str(row[\"receipts\"])\n",
    "#    row[\"tracking_numbers\"]   = str(row[\"tracking_numbers\"])\n",
    "#    row[\"notes\"]              = str(row[\"notes\"])\n",
    "#df = pd.DataFrame.from_records(output,index=[\"id\",\"warehouse_customer_id\",\"created_date\",\"updated_date\",\"purchase_order_number\",\"status\",\"raw_status\",\"supplier\",\"expected_arrival_date\",\"warehouse_id\",\"line_items\",\"receipts\",\"ship_from_address\",\"tracking_numbers\",\"notes\",\"external_system_url\"]) \n",
    "#df.to_csv(\"/Users/danieljacobini/Downloads/inbound_shipments.csv\")\n",
    "############################\n",
    "# Orders\n",
    "############################\n",
    "output = get_data(\"orders\")\n",
    "line_items = []\n",
    "for row in output:\n",
    "    line_items = line_items + [dict(item, **{'id':row[\"id\"]}) for item in row[\"line_items\"]]\n",
    "df = pd.DataFrame.from_records(line_items,index=[\"product_id\",\"sku\",\"quantity\",\"unit_price\",\"is_picked\",\"discount_amount\",\"id\"])\n",
    "df.to_csv(\"orders_line_items.csv\")\n",
    "for row in output:\n",
    "    row[\"ship_to_address\"] = str(row[\"ship_to_address\"])\n",
    "    row[\"line_items\"]      = str(row[\"line_items\"])\n",
    "    row[\"tags\"]            = str(row[\"tags\"])\n",
    "    row[\"shipments\"]       = str(row[\"shipments\"])\n",
    "df = pd.DataFrame.from_records(output,index=[\"id\",\"warehouse_customer_id\",\"created_date\",\"updated_date\",\"reference_id\",\"order_number\",\"status\",\"raw_status\",\"channel\",\"type\",\"trading_partner\",\"shipping_method\",\"invoice_currency_code\",\"total_price\",\"total_tax\",\"total_discount\",\"total_shipping\",\"ship_to_address\",\"line_items\",\"tags\",\"required_ship_date\",\"shipments\",\"external_system_url\"]) \n",
    "df.to_csv(\"orders.csv\")\n",
    "\n",
    "# takes about 20 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "from datetime import datetime, timedelta, date\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"=== INVENTORY TIME SERIES ANALYSIS SYSTEM ===\")\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load Datasets with Date Parsing \n",
    "inbound_shipments = pd.read_csv(\"inbound_shipments.csv\", \n",
    "                                parse_dates=['created_date', 'updated_date', 'expected_arrival_date'])\n",
    "\n",
    "inventory = pd.read_csv(\"inventory.csv\", \n",
    "                        parse_dates=['created_date', 'updated_date'])\n",
    "\n",
    "orders_line_items = pd.read_csv(\"orders_line_items.csv\")\n",
    "\n",
    "orders = pd.read_csv(\"orders.csv\", \n",
    "                     parse_dates=['created_date', 'updated_date', 'required_ship_date'])\n",
    "\n",
    "products = pd.read_csv(\"products.csv\", \n",
    "                       parse_dates=['created_date', 'updated_date'])\n",
    "\n",
    "shipping_methods = pd.read_csv(\"shipping_methods.csv\", \n",
    "                               parse_dates=['created_date', 'updated_date'])\n",
    "\n",
    "suppliers = pd.read_csv(\"suppliers.csv\")\n",
    "\n",
    "# Keep datetime columns as date objects (not converting to string)\n",
    "inbound_shipments['created_date'] = inbound_shipments['created_date'].dt.date\n",
    "inbound_shipments['updated_date'] = inbound_shipments['updated_date'].dt.date\n",
    "inbound_shipments['expected_arrival_date'] = inbound_shipments['expected_arrival_date'].dt.date\n",
    "\n",
    "inventory['created_date'] = inventory['created_date'].dt.date\n",
    "inventory['updated_date'] = inventory['updated_date'].dt.date\n",
    "\n",
    "orders['created_date'] = orders['created_date'].dt.date\n",
    "orders['updated_date'] = orders['updated_date'].dt.date\n",
    "orders['required_ship_date'] = orders['required_ship_date'].dt.date\n",
    "\n",
    "products['created_date'] = products['created_date'].dt.date\n",
    "products['updated_date'] = products['updated_date'].dt.date\n",
    "\n",
    "shipping_methods['created_date'] = shipping_methods['created_date'].dt.date\n",
    "shipping_methods['updated_date'] = shipping_methods['updated_date'].dt.date\n",
    "\n",
    "print(\"✓ Datasets loaded successfully\")\n",
    "\n",
    "# Helper Functions\n",
    "def inspect_dataset(df):\n",
    "    print(f\"\\n{df} Dataset Overview:\")\n",
    "    print(\"\\nHEAD:\\n\", df.head())\n",
    "    print(\"\\nINFO:\\n\")\n",
    "    print(df.info())\n",
    "    print(\"\\nMISSING VALUES:\\n\", df.isnull().sum())\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "    \n",
    "def safe_eval_list(item_list):\n",
    "    \"\"\"Safely evaluate string representations of lists\"\"\"\n",
    "    if isinstance(item_list, str):\n",
    "        try:\n",
    "            return ast.literal_eval(item_list)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    elif isinstance(item_list, list):\n",
    "        return item_list\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def extract_unit_quantity(item_list):\n",
    "    \"\"\"Extract unit_quantity from inventory_items\"\"\"\n",
    "    if isinstance(item_list, str):  # If it's stored as a string, convert it to a list\n",
    "        try:\n",
    "            item_list = ast.literal_eval(item_list)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return 0  # Return 0 if conversion fails\n",
    "    if isinstance(item_list, list) and len(item_list) > 0:\n",
    "        return item_list[0].get('unit_quantity', 0)  # Get unit_quantity from first item\n",
    "    return 0  # Return 0 if no valid data\n",
    "\n",
    "def parse_date(date_value):\n",
    "    \"\"\"Parse date value to date object (date only, no time)\"\"\"\n",
    "    if pd.isna(date_value):\n",
    "        return None\n",
    "    try:\n",
    "        if isinstance(date_value, str):\n",
    "            dt = datetime.fromisoformat(date_value.replace(\"Z\", \"+00:00\"))\n",
    "            return dt.date()\n",
    "        elif isinstance(date_value, datetime):\n",
    "            return date_value.date()\n",
    "        elif isinstance(date_value, date):\n",
    "            return date_value\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Extract unit_quantity from products\n",
    "print(\"Extracting unit_quantity from inventory_items...\")\n",
    "products['unit_quantity'] = products['inventory_items'].apply(extract_unit_quantity)\n",
    "print(f\"✓ Unit quantity extracted for {len(products)} products\")\n",
    "print(\"Sample unit_quantity values:\", products['unit_quantity'].head())\n",
    "\n",
    "def build_sales_time_series():\n",
    "    \"\"\"Build time series for sales data including returns (negative quantities)\"\"\"\n",
    "    print(\"Building sales time series...\")\n",
    "    \n",
    "    # Merge orders with line items to get dates\n",
    "    sales_data = orders_line_items.merge(\n",
    "        orders[['id', 'created_date']], \n",
    "        left_on='id', \n",
    "        right_on='id', \n",
    "        how='left'\n",
    "    ).rename(columns={'created_date': 'order_date'})\n",
    "    \n",
    "    # Group sales by SKU and create time series\n",
    "    sales_time_series = {}\n",
    "    \n",
    "    for sku in sales_data['sku'].unique():\n",
    "        sku_sales = sales_data[sales_data['sku'] == sku].copy()\n",
    "        \n",
    "        # Group by date and aggregate quantities for same-day transactions\n",
    "        daily_sales = defaultdict(lambda: {'quantity': 0, 'total_value': 0, 'unit_prices': []})\n",
    "        \n",
    "        for _, row in sku_sales.iterrows():\n",
    "            order_date = parse_date(row['order_date'])\n",
    "            if order_date:\n",
    "                daily_sales[order_date]['quantity'] += row['quantity']\n",
    "                unit_price = row.get('unit_price', 0)\n",
    "                daily_sales[order_date]['total_value'] += row['quantity'] * unit_price\n",
    "                daily_sales[order_date]['unit_prices'].append(unit_price)\n",
    "        # Convert to time series format\n",
    "        time_series = []\n",
    "        for order_date, data in daily_sales.items():\n",
    "            avg_unit_price = data['total_value'] / data['quantity'] if data['quantity'] != 0 else 0\n",
    "            time_series.append({\n",
    "                'date': order_date,  # Keep as date object\n",
    "                'quantity': data['quantity'],\n",
    "                'unit_price': avg_unit_price,\n",
    "                'total_value': data['total_value']\n",
    "            })\n",
    "        \n",
    "        # Sort by date\n",
    "        time_series.sort(key=lambda x: x['date'])\n",
    "        sales_time_series[sku] = time_series\n",
    "    \n",
    "    return sales_time_series\n",
    "\n",
    "def build_received_time_series():\n",
    "    \"\"\"Build time series for received inventory from inbound shipments\"\"\"\n",
    "    print(\"Building received inventory time series...\")\n",
    "    \n",
    "    received_time_series = {}\n",
    "    \n",
    "    # Group by SKU and date first\n",
    "    daily_receipts = defaultdict(lambda: defaultdict(lambda: {'quantity': 0, 'shipment_ids': [], 'purchase_orders': []}))\n",
    "    \n",
    "    for _, shipment in inbound_shipments.iterrows():\n",
    "        line_items = safe_eval_list(shipment['line_items'])\n",
    "        shipment_date = parse_date(shipment['created_date'])\n",
    "        \n",
    "        if not shipment_date or not line_items:\n",
    "            continue\n",
    "            \n",
    "        for item in line_items:\n",
    "            sku = item.get('sku')\n",
    "            quantity = item.get('quantity', item.get('received_quantity', 0))\n",
    "            \n",
    "            if sku and quantity:\n",
    "                daily_receipts[sku][shipment_date]['quantity'] += quantity\n",
    "                daily_receipts[sku][shipment_date]['shipment_ids'].append(shipment['id'])\n",
    "                daily_receipts[sku][shipment_date]['purchase_orders'].append(shipment.get('purchase_order_number', 'Unknown'))\n",
    "    \n",
    "    # Convert to time series format\n",
    "    for sku, date_data in daily_receipts.items():\n",
    "        time_series = []\n",
    "        for receipt_date, data in date_data.items():\n",
    "            time_series.append({\n",
    "                'date': receipt_date,  # Keep as date object\n",
    "                'quantity': data['quantity'],\n",
    "                'shipment_ids': list(set(data['shipment_ids'])),\n",
    "                'purchase_orders': list(set(data['purchase_orders']))\n",
    "            })\n",
    "        \n",
    "        # Sort by date\n",
    "        time_series.sort(key=lambda x: x['date'])\n",
    "        received_time_series[sku] = time_series\n",
    "    \n",
    "    return received_time_series\n",
    "\n",
    "def build_historical_inventory_corrected(sku, sales_ts, received_ts):\n",
    "    \"\"\"Calculate historical inventory using inventory.sellable as current inventory - CORRECTED VERSION\"\"\"\n",
    "    \n",
    "    # Get current inventory from inventory table's 'sellable' column\n",
    "    inventory_row = inventory[inventory['sku'] == sku]\n",
    "    if inventory_row.empty:\n",
    "        current_inventory = 0\n",
    "    else:\n",
    "        current_inventory = inventory_row.iloc[0]['sellable']\n",
    "    \n",
    "    # Find all transaction dates\n",
    "    all_dates = set()\n",
    "    if sku in sales_ts:\n",
    "        all_dates.update([entry['date'] for entry in sales_ts[sku]])\n",
    "    if sku in received_ts:\n",
    "        all_dates.update([entry['date'] for entry in received_ts[sku]])\n",
    "    \n",
    "    if not all_dates:\n",
    "        return []\n",
    "    \n",
    "    # Group transactions by date\n",
    "    daily_transactions = defaultdict(lambda: {'sales': 0, 'receipts': 0})\n",
    "    \n",
    "    if sku in sales_ts:\n",
    "        for sale in sales_ts[sku]:\n",
    "            sale_date = sale['date']\n",
    "            daily_transactions[sale_date]['sales'] += sale['quantity']\n",
    "    \n",
    "    if sku in received_ts:\n",
    "        for receipt in received_ts[sku]:\n",
    "            receipt_date = receipt['date']\n",
    "            daily_transactions[receipt_date]['receipts'] += receipt['quantity']\n",
    "    \n",
    "    # Create sorted list of dates (most recent first for backwards calculation)\n",
    "    sorted_dates = sorted(all_dates, reverse=True)\n",
    "    \n",
    "    # Calculate historical inventory by working backwards from current\n",
    "    historical_inventory = []\n",
    "    inventory_after_date = current_inventory\n",
    "    \n",
    "    # Work backwards through dates\n",
    "    for transaction_date in sorted_dates:\n",
    "        daily_data = daily_transactions[transaction_date]\n",
    "        net_change = daily_data['receipts'] - daily_data['sales']\n",
    "        \n",
    "        # Record the inventory level AFTER this date's transactions\n",
    "        historical_inventory.append({\n",
    "            'date': transaction_date,  # Keep as date object\n",
    "            'inventory': int(inventory_after_date),\n",
    "            'sales': int(daily_data['sales']),\n",
    "            'receipts': int(daily_data['receipts']),\n",
    "            'net_change': int(net_change)\n",
    "        })\n",
    "        \n",
    "        # Calculate what inventory was BEFORE this date's transactions (for next iteration)\n",
    "        inventory_after_date = inventory_after_date - net_change\n",
    "    \n",
    "    # Sort chronologically (oldest first)\n",
    "    historical_inventory.sort(key=lambda x: x['date'])\n",
    "    \n",
    "    return historical_inventory\n",
    "\n",
    "\n",
    "def create_corrected_sku_dataframe():\n",
    "    \"\"\"Create dataframe with corrected inventory and requested columns only\"\"\"\n",
    "    print(\"Creating corrected SKU dataframe...\")\n",
    "    \n",
    "    # Start with products table for SKU, name, created_date, and unit_price\n",
    "    base_data = products[['sku', 'name', 'created_date', 'unit_price']].copy()\n",
    "    \n",
    "    # Add updated_date from inventory table\n",
    "    inventory_updates = inventory[['sku', 'updated_date']].rename(columns={'updated_date': 'updated_date'})\n",
    "    base_data = base_data.merge(inventory_updates, on='sku', how='left')\n",
    "    \n",
    "    # Initialize time series columns\n",
    "    base_data['historical_inventory'] = None\n",
    "    base_data['historical_sales'] = None\n",
    "    base_data['historical_received'] = None\n",
    "    \n",
    "    print(f\"Processing {len(base_data)} SKUs...\")\n",
    "    \n",
    "    # Process each SKU\n",
    "    for idx, row in base_data.iterrows():\n",
    "        sku = row['sku']\n",
    "        \n",
    "        # Build corrected time series for this SKU\n",
    "        hist_inventory = build_historical_inventory_corrected(sku, sales_ts, received_ts)\n",
    "        hist_sales = sales_ts.get(sku, [])\n",
    "        hist_received = received_ts.get(sku, [])\n",
    "        \n",
    "        # Store time series\n",
    "        base_data.at[idx, 'historical_inventory'] = hist_inventory\n",
    "        base_data.at[idx, 'historical_sales'] = hist_sales\n",
    "        base_data.at[idx, 'historical_received'] = hist_received\n",
    "    \n",
    "    return base_data\n",
    "\n",
    "\n",
    "# Execute the corrected analysis\n",
    "print(\"\\n=== EXECUTING CORRECTED ANALYSIS ===\")\n",
    "\n",
    "# Build time series (sales and received remain the same as they were working correctly)\n",
    "sales_ts = build_sales_time_series()\n",
    "print(f\"✓ Sales time series built for {len(sales_ts)} SKUs\")\n",
    "\n",
    "received_ts = build_received_time_series()\n",
    "print(f\"✓ Received inventory time series built for {len(received_ts)} SKUs\")\n",
    "\n",
    "# Create corrected comprehensive dataframe\n",
    "sku_timeseries_df_corrected = create_corrected_sku_dataframe()\n",
    "print(f\"✓ Corrected dataframe created with {len(sku_timeseries_df_corrected)} SKUs\")\n",
    "\n",
    "# Display sample of corrected data\n",
    "print(\"\\nSample of corrected data:\")\n",
    "print(sku_timeseries_df_corrected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sku_timeseries_df_corrected\n",
    "inspect_dataset(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('sku_data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all SKUs\n",
    "for idx, row in df.iterrows():\n",
    "    sku = row['sku']\n",
    "    print(f\"Row for SKU {sku}:\")\n",
    "    for col, value in row.items():\n",
    "        print(f\"  {col}: {value}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find SKUs with negative quantities in historical_sales\n",
    "negative_quantity_skus = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sku = row['sku']\n",
    "    historical_sales = row['historical_sales']\n",
    "    \n",
    "    # Check each sale in historical_sales\n",
    "    for sale in historical_sales:\n",
    "        if sale['quantity'] < 0:\n",
    "            negative_quantity_skus.append({\n",
    "                'sku': sku,\n",
    "                'date': sale['date'],\n",
    "                'quantity': sale['quantity']\n",
    "            })\n",
    "\n",
    "# Display results\n",
    "if negative_quantity_skus:\n",
    "    print(\"\\nFound SKUs with negative quantities:\")\n",
    "    for item in negative_quantity_skus:\n",
    "        print(f\"SKU: {item['sku']}, Date: {item['date']}, Quantity: {item['quantity']}\")\n",
    "else:\n",
    "    print(\"\\nNo SKUs found with negative quantities\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
